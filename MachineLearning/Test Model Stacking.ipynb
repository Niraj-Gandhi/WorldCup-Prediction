{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../DataFormating/compressed_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stage', 'Home Team Name', 'Home Team Goals', 'Away Team Goals',\n",
       "       'Away Team Name', 'Attendance', 'Half-time Home Goals',\n",
       "       'Half-time Away Goals', 'Home Team Initials', 'Away Team Initials'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Home Team Goals\", \"Away Team Goals\",\n",
    "               \"Half-time Home Goals\", \"Half-time Away Goals\", \n",
    "               \"Home Team Initials\", \"Away Team Initials\"], axis=1)\n",
    "\n",
    "y = []\n",
    "for i in range(len(data)):\n",
    "    home_team_goals = data.iloc[i][\"Home Team Goals\"]\n",
    "    away_team_goals = data.iloc[i][\"Away Team Goals\"]\n",
    "    \n",
    "    if home_team_goals > away_team_goals:\n",
    "        y.append(1)\n",
    "    elif home_team_goals < away_team_goals:\n",
    "        y.append(2)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "assert len(X) == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode textual features from the `X` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cup_teams = [\n",
    "    \"Egypt\",\n",
    "    \"Morocco\",\n",
    "    \"Nigeria\",\n",
    "    \"Senegal\",\n",
    "    \"Tunisia\",\n",
    "    \"Australia\",\n",
    "    \"IR Iran\",\n",
    "    \"Japan\",\n",
    "    \"Korea DPR\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"Belgium\",\n",
    "    \"Croatia\",\n",
    "    \"Denmark\",\n",
    "    \"England\",\n",
    "    \"France\",\n",
    "    \"Germany\",\n",
    "    \"Iceland\",\n",
    "    \"Poland\",\n",
    "    \"Portugal\",\n",
    "    \"Russia\",\n",
    "    \"Serbia\",\n",
    "    \"Spain\",\n",
    "    \"Sweden\",\n",
    "    \"Switzerland\",\n",
    "    \"Costa Rica\",\n",
    "    \"Mexico\",\n",
    "    \"Panama\",\n",
    "    \"Argentina\",\n",
    "    \"Brazil\",\n",
    "    \"Colombia\",\n",
    "    \"Peru\",\n",
    "    \"Uruguay\"\n",
    "]\n",
    "\n",
    "team_names = list(data[\"Home Team Name\"].unique()) + list(data[\"Away Team Name\"].unique()) + word_cup_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_encoder = LabelEncoder().fit(X[\"Stage\"])\n",
    "team_name_encoder = LabelEncoder().fit(team_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Stage\"] = stage_encoder.transform(X[\"Stage\"])\n",
    "X[\"Home Team Name\"] = team_name_encoder.transform(X[\"Home Team Name\"])\n",
    "X[\"Away Team Name\"] = team_name_encoder.transform(X[\"Away Team Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"Stage\", \"Home Team Name\", \"Away Team Name\",\n",
    "    \"Attendance\", \"Overall\",\n",
    "    \"Mean Home Team Goals\", \"Mean Away Team Goals\"\n",
    "]\n",
    "\n",
    "COLUMNS = []\n",
    "\n",
    "for column_name in X.columns:\n",
    "    for feature_name in feature_names:\n",
    "        if feature_name in column_name:\n",
    "            COLUMNS.append(column_name)\n",
    "            break\n",
    "\n",
    "X = X[COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stage',\n",
       " 'Home Team Name',\n",
       " 'Away Team Name',\n",
       " 'Attendance',\n",
       " 'Player 1 Overall Diff',\n",
       " 'Player 2 Overall Diff',\n",
       " 'Player 3 Overall Diff',\n",
       " 'Player 4 Overall Diff',\n",
       " 'Player 5 Overall Diff',\n",
       " 'Player 6 Overall Diff',\n",
       " 'Player 7 Overall Diff',\n",
       " 'Player 8 Overall Diff',\n",
       " 'Player 9 Overall Diff',\n",
       " 'Player 10 Overall Diff',\n",
       " 'Player 11 Overall Diff',\n",
       " 'Mean Home Team Goals',\n",
       " 'Mean Away Team Goals']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning / Evaluation Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStacking(object):\n",
    "    def __init__(self, base_model, *stacked_models):\n",
    "        self.base_model = base_model\n",
    "        self.stacked_models = stacked_models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        data = X.copy()\n",
    "        for i in range(len(self.stacked_models)):\n",
    "            self.stacked_models[i].fit(X, y)\n",
    "            pred = self.stacked_models[i].predict(X)\n",
    "            data[\"Model-\"+str(i)] = pred\n",
    "\n",
    "        self.base_model.fit(data, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        data = X.copy()\n",
    "        for i in range(len(self.stacked_models)):\n",
    "            pred = self.stacked_models[i].predict(X)\n",
    "            data[\"Model-\"+str(i)] = pred\n",
    "\n",
    "        return self.base_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X, y, cv=10):\n",
    "    score = 0\n",
    "    for _ in range(cv):\n",
    "        _model = deepcopy(model)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        _model.fit(X_train, y_train)\n",
    "        y_pred = _model.predict(X_test)\n",
    "        score += accuracy_score(y_test, y_pred)\n",
    "\n",
    "        if cv == 1:\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Test set accuracy score: \", score/cv, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelStacking(\n",
    "    RandomForestClassifier(n_estimators=10, max_depth=3, bootstrap=True, n_jobs=-1),\n",
    "\n",
    "    ExtraTreesClassifier(n_estimators=1000, max_depth=10, bootstrap=True, n_jobs=-1),\n",
    "\n",
    "    XGBClassifier(n_estimators=4000, max_depth=20, learning_rate=0.03, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score:  0.651063829787234 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/Documents/WorldCup-Prediction/.venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_model(model, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
